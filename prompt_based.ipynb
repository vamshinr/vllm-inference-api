{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH1kVpV6a1oB"
      },
      "outputs": [],
      "source": [
        "def classify_query(query):\n",
        "    # Basic keyword matching (can be replaced with more sophisticated methods)\n",
        "    if \"who\" in query or \"what\" in query:\n",
        "        return \"factual\"\n",
        "    elif \"summarize\" in query or \"overview\" in query:\n",
        "        return \"summarization\"\n",
        "    elif \"opinion\" in query or \"thoughts\" in query:\n",
        "        return \"opinion\"\n",
        "    else:\n",
        "        return \"general\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_factual_prompt(query, documents):\n",
        "    return (\n",
        "        \"You are an expert. Based on the following documents, answer the question factually.\\n\\n\"\n",
        "        \"User Query: {query}\\n\\n\"\n",
        "        \"Relevant Documents:\\n{documents}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    ).format(query=query, documents=documents)\n"
      ],
      "metadata": {
        "id": "x4wPF2RUa7e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_summarization_prompt(query, documents):\n",
        "    return (\n",
        "        \"Please summarize the following information in response to the query.\\n\\n\"\n",
        "        \"User Query: {query}\\n\\n\"\n",
        "        \"Documents:\\n{documents}\\n\\n\"\n",
        "        \"Summary:\"\n",
        "    ).format(query=query, documents=documents)\n"
      ],
      "metadata": {
        "id": "YvwRQC2Qa-0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_opinion_prompt(query, documents):\n",
        "    return (\n",
        "        \"Provide an informed opinion based on the documents below in response to the query.\\n\\n\"\n",
        "        \"User Query: {query}\\n\\n\"\n",
        "        \"Relevant Documents:\\n{documents}\\n\\n\"\n",
        "        \"Opinion:\"\n",
        "    ).format(query=query, documents=documents)\n"
      ],
      "metadata": {
        "id": "V5T0PH4HbBsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dynamic_prompt(query, documents):\n",
        "    category = classify_query(query)\n",
        "\n",
        "    if category == \"factual\":\n",
        "        return get_factual_prompt(query, documents)\n",
        "    elif category == \"summarization\":\n",
        "        return get_summarization_prompt(query, documents)\n",
        "    elif category == \"opinion\":\n",
        "        return get_opinion_prompt(query, documents)\n",
        "    else:\n",
        "        # Use a general template if no specific category is matched\n",
        "        return (\n",
        "            \"Based on the following information, respond to the query.\\n\\n\"\n",
        "            \"User Query: {query}\\n\\n\"\n",
        "            \"Documents:\\n{documents}\\n\\n\"\n",
        "            \"Response:\"\n",
        "        ).format(query=query, documents=documents)\n"
      ],
      "metadata": {
        "id": "8fHvtPztbEKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
        "\n",
        "# Load LLaMA2 model and tokenizer\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"path_to_llama2\")\n",
        "model = LlamaForCausalLM.from_pretrained(\"path_to_llama2\")\n",
        "\n",
        "def get_model_response(query, documents):\n",
        "    prompt = generate_dynamic_prompt(query, documents)\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    output = model.generate(input_ids, max_length=200)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Example user query and retrieved documents\n",
        "query = \"What is the significance of the Magna Carta?\"\n",
        "documents = \"The Magna Carta, signed in 1215, is a foundational document in the history of democracy...\"\n",
        "\n",
        "response = get_model_response(query, documents)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "4euPOd5rbFD0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}